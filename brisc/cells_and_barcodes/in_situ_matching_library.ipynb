{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"becalia_rabies_barseq/BRAC8498.3e/chamber_07\"\n",
    "processed_path = Path(\"/nemo/project/proj-znamenp-barseq/processed/becalia_rabies_barseq/BRAC8498.3e/\")\n",
    "ara_is_starters = pd.read_pickle(processed_path / \"analysis\" / \"merged_cell_df_curated_mcherry.pkl\")\n",
    "ara_is_starters = ara_is_starters[ara_is_starters[\"main_barcode\"].notna()]\n",
    "in_situ_barcodes = ara_is_starters[\"all_barcodes\"].explode().unique()\n",
    "in_situ_barcodes = pd.DataFrame(in_situ_barcodes, columns=[\"sequence\"])\n",
    "\n",
    "barcode_library_sequence_path = Path(\"/nemo/lab/znamenskiyp/home/shared/projects/barcode_diversity_analysis/collapsed_barcodes/RV35/RV35_bowtie_ed2.txt\")\n",
    "rv35_library = pd.read_csv(barcode_library_sequence_path, sep=\"\\t\", header=None)\n",
    "rv35_library[\"10bp_seq\"] = rv35_library[1].str.slice(0, 10)\n",
    "rv35_library.rename(columns={0: \"counts\", 1: \"sequence\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate edit distances between in situ barcodes and R2 library barcodes\n",
    "# Hamming distance function - used for final plots\n",
    "def hamming_distance(str1, str2):\n",
    "    return sum(c1 != c2 for c1, c2 in zip(str1, str2))\n",
    "\n",
    "# Define a function to calculate the minimum edit distance\n",
    "def calculate_min_edit_distance(insitu_bc):\n",
    "    edit_distances = np.fromiter(\n",
    "        (hamming_distance(insitu_bc, lib_bc) for lib_bc in lib_10bp_seq), int\n",
    "    )\n",
    "    min_edit_distance_idx = np.argmin(edit_distances)\n",
    "    min_edit_distance = edit_distances[min_edit_distance_idx]\n",
    "    lib_bc_sequence = rv35_library.loc[min_edit_distance_idx, \"10bp_seq\"]\n",
    "    lib_bc_count = rv35_library.loc[min_edit_distance_idx, \"counts\"]\n",
    "    return min_edit_distance, lib_bc_sequence, lib_bc_count\n",
    "\n",
    "redo = False\n",
    "\n",
    "lib_10bp_seq = np.array(rv35_library[\"10bp_seq\"])\n",
    "if redo:\n",
    "    # Wrap the outer loop with tqdm for progress tracking\n",
    "    with Pool() as pool:\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                pool.imap(calculate_min_edit_distance, in_situ_barcodes[\"sequence\"]),\n",
    "                total=len(in_situ_barcodes),\n",
    "                desc=\"Calculating edit distances\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Extract the results from the list of tuples\n",
    "    min_edit_distances, lib_bc_sequences, lib_bc_counts = zip(*results)\n",
    "\n",
    "    # Assign the minimum edit distances, lib_bc sequences, and counts to new columns in in_situ_barcodes\n",
    "    in_situ_barcodes[\"ham_min_edit_distance\"] = min_edit_distances\n",
    "    in_situ_barcodes[\"ham_lib_bc_sequence\"] = lib_bc_sequences\n",
    "    in_situ_barcodes[\"ham_lib_bc_counts\"] = lib_bc_counts\n",
    "\n",
    "\n",
    "    # Generate random DNA sequences\n",
    "    num_sequences = in_situ_barcodes.shape[0]\n",
    "    sequence_length = 10\n",
    "    random_seed = 42  # add some meaning\n",
    "    np.random.seed(random_seed)\n",
    "    random_sequences = np.array(\n",
    "        [\n",
    "            \"\".join(np.random.choice([\"A\", \"C\", \"G\", \"T\"], size=sequence_length))\n",
    "            for _ in range(num_sequences)\n",
    "        ],\n",
    "        dtype=object,\n",
    "    )\n",
    "\n",
    "    # Wrap the outer loop with tqdm for progress tracking\n",
    "    with Pool() as pool:\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                pool.imap(calculate_min_edit_distance, random_sequences),\n",
    "                total=len(random_sequences),\n",
    "                desc=\"Calculating edit distances\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Extract the results from the list of tuples\n",
    "    min_edit_distances, lib_bc_sequences, lib_bc_counts = zip(*results)\n",
    "\n",
    "    random_df = pd.DataFrame(random_sequences, columns=[\"random_sequences\"])\n",
    "    # Assign the minimum edit distances, lib_bc sequences, and counts to new columns in in_situ_barcodes\n",
    "    random_df[\"min_edit_distance\"] = min_edit_distances\n",
    "    random_df[\"lib_bc_sequence\"] = lib_bc_sequences\n",
    "    random_df[\"lib_bc_counts\"] = lib_bc_counts\n",
    "    random_df.to_pickle(\n",
    "        \"/nemo/lab/znamenskiyp/home/users/becalia/data/BRYC65.1d/random_2252_barcodes.pkl\"\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    in_situ_barcodes = pd.read_pickle(\n",
    "        \"in_situ_barcodes.pkl\"\n",
    "    )\n",
    "    random_df = pd.read_pickle(\n",
    "        \"/nemo/lab/znamenskiyp/home/users/becalia/data/BRYC65.1d/random_2252_barcodes.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_barcodes(barcode_list):\n",
    "    return [bc[:10] for bc in barcode_list]\n",
    "\n",
    "ara_is_starters['all_barcodes'] = ara_is_starters['all_barcodes'].apply(shorten_barcodes)\n",
    "ara_is_starters['main_barcode'] = ara_is_starters['main_barcode'].apply(lambda x: x[:10])\n",
    "\n",
    "non_starter_barcodes_counts = (\n",
    "    ara_is_starters[ara_is_starters[\"is_starter\"] == False][\"all_barcodes\"]\n",
    "    .explode()\n",
    "    .value_counts()\n",
    ")\n",
    "barcoded_cells = ara_is_starters[ara_is_starters[\"main_barcode\"].notna()]\n",
    "\n",
    "# Exploding all_barcodes to allow searching in individual barcodes\n",
    "exploded_data = ara_is_starters.explode(\"all_barcodes\")\n",
    "# Filtering cells with valid barcodes in all_barcodes\n",
    "barcoded_cells = exploded_data[exploded_data[\"all_barcodes\"].notna()]\n",
    "# Filtering cells where is_starter is False\n",
    "non_starter_cells = barcoded_cells[barcoded_cells['is_starter'] == False]\n",
    "# Finding all barcodes where is_starter is True\n",
    "starter_barcodes = barcoded_cells[barcoded_cells['is_starter'] == True]['all_barcodes'].unique()\n",
    "# Subset 1: Non-starters with corresponding starters\n",
    "non_starter_with_starter = non_starter_cells[non_starter_cells['all_barcodes'].isin(starter_barcodes)]\n",
    "# Subset 2: Non-starters without corresponding starters\n",
    "non_starter_without_starter = non_starter_cells[~non_starter_cells['all_barcodes'].isin(starter_barcodes)]\n",
    "# Grouping and counting for both subsets\n",
    "counts_with_starter = non_starter_with_starter.groupby('all_barcodes').size()\n",
    "counts_without_starter = non_starter_without_starter.groupby('all_barcodes').size()\n",
    "\n",
    "\n",
    "# Group and filter for non_starter_without_starter\n",
    "grouped_barcodes_without = non_starter_without_starter.groupby('all_barcodes')\n",
    "groups_of_size_1_without = grouped_barcodes_without.filter(lambda x: len(x) == 1)\n",
    "groups_of_size_over_10_without = grouped_barcodes_without.filter(lambda x: len(x) > 10)\n",
    "unique_single_pre_no_starter = groups_of_size_1_without.all_barcodes.unique()\n",
    "unique_many_pre_no_starter = groups_of_size_over_10_without.all_barcodes.unique()\n",
    "\n",
    "# Group and filter for non_starter_with_starter\n",
    "grouped_barcodes_with = non_starter_with_starter.groupby('all_barcodes')\n",
    "groups_of_size_1_with = grouped_barcodes_with.filter(lambda x: len(x) == 1)\n",
    "groups_of_size_over_10_with = grouped_barcodes_with.filter(lambda x: len(x) > 10)\n",
    "unique_single_pre_with_starter = groups_of_size_1_with.all_barcodes.unique()\n",
    "unique_many_pre_with_starter = groups_of_size_over_10_with.all_barcodes.unique()\n",
    "\n",
    "\n",
    "unique_single_pre_no_starter = pd.DataFrame(unique_single_pre_no_starter, columns=[\"sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(str1, str2):\n",
    "    return sum(c1 != c2 for c1, c2 in zip(str1, str2))\n",
    "\n",
    "# Define a function to calculate the minimum edit distance\n",
    "def calculate_min_edit_distance(insitu_bc):\n",
    "    edit_distances = np.fromiter(\n",
    "        (hamming_distance(insitu_bc, lib_bc) for lib_bc in lib_10bp_seq), int\n",
    "    )\n",
    "    min_edit_distance_idx = np.argmin(edit_distances)\n",
    "    min_edit_distance = edit_distances[min_edit_distance_idx]\n",
    "    lib_bc_sequence = rv35_library.loc[min_edit_distance_idx, \"10bp_seq\"]\n",
    "    lib_bc_count = rv35_library.loc[min_edit_distance_idx, \"counts\"]\n",
    "    return min_edit_distance, lib_bc_sequence, lib_bc_count\n",
    "\n",
    "# Wrap the outer loop with tqdm for progress tracking\n",
    "with Pool() as pool:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            pool.imap(calculate_min_edit_distance, unique_single_pre_no_starter[\"sequence\"]),\n",
    "            total=len(unique_single_pre_no_starter),\n",
    "            desc=\"Calculating edit distances\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Extract the results from the list of tuples\n",
    "min_edit_distances, lib_bc_sequences, lib_bc_counts = zip(*results)\n",
    "\n",
    "# Assign the minimum edit distances, lib_bc sequences, and counts to new columns in in_situ_barcodes\n",
    "unique_single_pre_no_starter[\"ham_min_edit_distance\"] = min_edit_distances\n",
    "unique_single_pre_no_starter[\"ham_lib_bc_sequence\"] = lib_bc_sequences\n",
    "unique_single_pre_no_starter[\"ham_lib_bc_counts\"] = lib_bc_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_situ_perfect_match = in_situ_barcodes[\n",
    "    in_situ_barcodes[\"ham_min_edit_distance\"] == 0\n",
    "]\n",
    "random_perfect_match = random_df[random_df[\"min_edit_distance\"] == 0]\n",
    "merged_perfect_match = in_situ_barcodes[in_situ_barcodes[\"ham_min_edit_distance\"] == 0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_counts = ara_is_starters[ara_is_starters[\"is_starter\"] == True].all_barcodes.explode().value_counts()\n",
    "barcodes_more_than_one = barcode_counts[barcode_counts > 1].index.tolist()\n",
    "filtered_df = in_situ_barcodes[in_situ_barcodes[\"sequence\"].str[:len(max(barcodes_more_than_one, key=len))].isin(barcodes_more_than_one)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Adjust subplot layout to include histogram axes\n",
    "fig, axes = plt.subplots(\n",
    "    7, 1, sharex=True, figsize=(8, 10),\n",
    "    gridspec_kw={\"height_ratios\": [0.2, 0.08, 0.2, 0.08, 0.2, 0.08, 0.6]}\n",
    ")\n",
    "\n",
    "# Histogram Axes\n",
    "axh0, ax0, axh1, ax1, axh2, ax2, ax3 = axes  # Assign axes to variables\n",
    "\n",
    "# Define bin edges for histogram\n",
    "bin_edges = np.logspace(0, 6, num=80)  # Log bins for better visualization\n",
    "\n",
    "# Define jitter scale\n",
    "jitter_scale = 0.2  \n",
    "\n",
    "### HISTOGRAM 1 (Above ax0)\n",
    "data0 = in_situ_perfect_match[\"ham_lib_bc_counts\"].values\n",
    "axh0.hist(data0, bins=bin_edges, color=\"#2ca02c\", alpha=0.6)\n",
    "#axh0.set_yticks([])  # Remove y-ticks\n",
    "#axh0.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "### BOX 1\n",
    "ax0.set_title(\"All barcode sequences\")\n",
    "ax0.boxplot(\n",
    "    data0, vert=False, widths=0.7,\n",
    "    boxprops=dict(color=\"#2ca02c\"), whiskerprops=dict(color=\"#2ca02c\"),\n",
    "    flierprops=dict(marker=\"o\", markersize=3, alpha=0.1, color=\"#2ca02c\"),\n",
    "    capprops=dict(color=\"#2ca02c\"), medianprops=dict(color=\"red\")\n",
    ")\n",
    "ax0.axis('off')\n",
    "y_jitter0 = 1 + (np.random.rand(len(data0)) - 0.5) * 2 * jitter_scale\n",
    "ax0.scatter(data0, y_jitter0, s=5, alpha=0.2, color=\"#2ca02c\")\n",
    "\n",
    "### HISTOGRAM 2 (Above ax1)\n",
    "data1 = unique_single_pre_no_starter[\"ham_lib_bc_counts\"].values\n",
    "axh1.hist(data1, bins=bin_edges, color=\"#ff7f0e\", alpha=0.6)\n",
    "#axh1.set_yticks([])\n",
    "#axh1.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "### BOX 2\n",
    "ax1.set_title(\"Single presyn with no starter barcode sequences\")\n",
    "ax1.boxplot(\n",
    "    data1, vert=False, widths=0.7,\n",
    "    boxprops=dict(color=\"#ff7f0e\"), whiskerprops=dict(color=\"#ff7f0e\"),\n",
    "    flierprops=dict(marker=\"o\", markersize=3, alpha=0.1, color=\"#ff7f0e\"),\n",
    "    capprops=dict(color=\"#ff7f0e\"), medianprops=dict(color=\"red\")\n",
    ")\n",
    "ax1.axis('off')\n",
    "y_jitter1 = 1 + (np.random.rand(len(data1)) - 0.5) * 2 * jitter_scale\n",
    "ax1.scatter(data1, y_jitter1, s=5, alpha=0.2, color=\"#ff7f0e\")\n",
    "\n",
    "### HISTOGRAM 3 (Above ax2)\n",
    "data2 = random_perfect_match[\"lib_bc_counts\"].values\n",
    "axh2.hist(data2, bins=bin_edges, color=\"#1f77b4\", alpha=0.6)\n",
    "#axh2.set_yticks([])\n",
    "#axh2.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "### BOX 3\n",
    "ax2.set_title(\"Randomly generated barcode sequences\")\n",
    "ax2.boxplot(\n",
    "    data2, vert=False, widths=0.7,\n",
    "    boxprops=dict(color=\"#1f77b4\"), whiskerprops=dict(color=\"#1f77b4\"),\n",
    "    flierprops=dict(marker=\"o\", markersize=3, alpha=0.1, color=\"#1f77b4\"),\n",
    "    capprops=dict(color=\"#1f77b4\"), medianprops=dict(color=\"red\")\n",
    ")\n",
    "ax2.axis('off')\n",
    "y_jitter2 = 1 + (np.random.rand(len(data2)) - 0.5) * 2 * jitter_scale\n",
    "ax2.scatter(data2, y_jitter2, s=5, alpha=0.2, color=\"#1f77b4\")\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "# PDF Histogram on ax3\n",
    "sequences = np.flip(rv35_library[\"counts\"])\n",
    "edge_positions = sequences.searchsorted(bin_edges)\n",
    "counts = np.zeros(len(bin_edges) - 1)\n",
    "for i in range(len(bin_edges) - 1):\n",
    "    parts = edge_positions[i : i + 2]\n",
    "    counts[i] = sequences[parts[0] : parts[1]].sum()\n",
    "counts /= np.sum(sequences)\n",
    "\n",
    "ax3.plot(bin_edges[:-1], counts, drawstyle=\"steps-post\", linewidth=0)\n",
    "ax3.fill_between(bin_edges[:-1], 0, counts, step=\"post\", alpha=0.6, color=\"k\")\n",
    "ax3.set_xlabel(\"Library barcode abundance\")\n",
    "ax3.set_ylabel(r\"Percentage of total library sequences\")\n",
    "ax3.set_xscale(\"log\")\n",
    "ax3.xaxis.set_major_locator(mticker.FixedLocator(locs=np.logspace(0, 6, 5)))\n",
    "ax3.xaxis.set_minor_locator(mticker.LogLocator(numticks=999, subs=\"auto\"))\n",
    "for label in ax3.xaxis.get_ticklabels()[1::2]:\n",
    "    label.set_visible(False)\n",
    "yticks = [0, 0.0125, 0.025, 0.0375, 0.05]\n",
    "ax3.set_yticks(ticks=yticks)\n",
    "ax3.set_yticklabels(labels=[0.00, 1.25, 2.50, 3.75, 5.00])\n",
    "ax3.set_xlim(None, 1000000)\n",
    "ax3.set_ylim(0, 0.05)\n",
    "ax3.yaxis.grid(False)\n",
    "\n",
    "\n",
    "# Enable ticks only for histogram axes\n",
    "for axh in [axh0, axh1, axh2]:\n",
    "    axh.tick_params(axis='both', which='both', direction='out')  # Show ticks\n",
    "    axh.xaxis.set_visible(True)  # Ensure x-axis is visible\n",
    "    axh.yaxis.set_visible(True)  # Ensure y-axis is visible\n",
    "\n",
    "# Disable ticks for boxplots\n",
    "for ax in [ax0, ax1, ax2]:\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "\n",
    "# Despine function\n",
    "def despine(ax):\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Apply despine to all subplots\n",
    "for ax in (axh0, ax0, axh1, ax1, axh2, ax2, ax3):\n",
    "    despine(ax)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_single_pre_no_starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Adjust subplot layout to include histogram axes\n",
    "fig, axes = plt.subplots(\n",
    "    9, 1, sharex=True, figsize=(8, 12),\n",
    "    gridspec_kw={\"height_ratios\": [0.2, 0.08, 0.2, 0.08, 0.2, 0.08, 0.2, 0.08, 0.6]}\n",
    ")\n",
    "\n",
    "# Histogram Axes\n",
    "axh0, ax0, axh1, ax1, axh2, ax2, axh3, ax3, ax4 = axes  # Assign axes to variables\n",
    "\n",
    "# Define bin edges for histogram\n",
    "bin_edges = np.logspace(0, 6, num=80)  # Log bins for better visualization\n",
    "\n",
    "# Define jitter scale\n",
    "jitter_scale = 0.2  \n",
    "\n",
    "### HISTOGRAM 1 (Above ax0)\n",
    "data0 = in_situ_perfect_match[\"ham_lib_bc_counts\"].values\n",
    "axh0.hist(data0, bins=bin_edges, color=\"#2ca02c\", alpha=0.6)\n",
    "#axh0.set_yticks([])  # Remove y-ticks\n",
    "#axh0.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "### BOX 1\n",
    "ax0.set_title(\"All barcode sequences\")\n",
    "ax0.boxplot(\n",
    "    data0, vert=False, widths=0.7,\n",
    "    boxprops=dict(color=\"#2ca02c\"), whiskerprops=dict(color=\"#2ca02c\"),\n",
    "    flierprops=dict(marker=\"o\", markersize=3, alpha=0.1, color=\"#2ca02c\"),\n",
    "    capprops=dict(color=\"#2ca02c\"), medianprops=dict(color=\"red\")\n",
    ")\n",
    "ax0.axis('off')\n",
    "y_jitter0 = 1 + (np.random.rand(len(data0)) - 0.5) * 2 * jitter_scale\n",
    "ax0.scatter(data0, y_jitter0, s=5, alpha=0.2, color=\"#2ca02c\")\n",
    "\n",
    "### HISTOGRAM 2 (Above ax1)\n",
    "data1 = unique_single_pre_no_starter[\"ham_lib_bc_counts\"].values\n",
    "axh1.hist(data1, bins=bin_edges, color=\"#ff7f0e\", alpha=0.6)\n",
    "#axh1.set_yticks([])\n",
    "#axh1.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "### BOX 2\n",
    "ax1.set_title(\"Single presyn with no starter barcode sequences\")\n",
    "ax1.boxplot(\n",
    "    data1, vert=False, widths=0.7,\n",
    "    boxprops=dict(color=\"#ff7f0e\"), whiskerprops=dict(color=\"#ff7f0e\"),\n",
    "    flierprops=dict(marker=\"o\", markersize=3, alpha=0.1, color=\"#ff7f0e\"),\n",
    "    capprops=dict(color=\"#ff7f0e\"), medianprops=dict(color=\"red\")\n",
    ")\n",
    "ax1.axis('off')\n",
    "y_jitter1 = 1 + (np.random.rand(len(data1)) - 0.5) * 2 * jitter_scale\n",
    "ax1.scatter(data1, y_jitter1, s=5, alpha=0.2, color=\"#ff7f0e\")\n",
    "\n",
    "### HISTOGRAM 3 (Above ax2)\n",
    "data2 = random_perfect_match[\"lib_bc_counts\"].values\n",
    "axh2.hist(data2, bins=bin_edges, color=\"#1f77b4\", alpha=0.6)\n",
    "#axh2.set_yticks([])\n",
    "#axh2.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "### BOX 3\n",
    "ax2.set_title(\"Randomly generated barcode sequences\")\n",
    "ax2.boxplot(\n",
    "    data2, vert=False, widths=0.7,\n",
    "    boxprops=dict(color=\"#1f77b4\"), whiskerprops=dict(color=\"#1f77b4\"),\n",
    "    flierprops=dict(marker=\"o\", markersize=3, alpha=0.1, color=\"#1f77b4\"),\n",
    "    capprops=dict(color=\"#1f77b4\"), medianprops=dict(color=\"red\")\n",
    ")\n",
    "ax2.axis('off')\n",
    "y_jitter2 = 1 + (np.random.rand(len(data2)) - 0.5) * 2 * jitter_scale\n",
    "ax2.scatter(data2, y_jitter2, s=5, alpha=0.2, color=\"#1f77b4\")\n",
    "\n",
    "### HISTOGRAM 4 (Above ax3)\n",
    "data3 = filtered_df[\"column_name\"].values  # Replace 'column_name' with the actual column name\n",
    "axh3.hist(data3, bins=bin_edges, color=\"#d62728\", alpha=0.6)\n",
    "#axh3.set_yticks([])\n",
    "#axh3.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "### BOX 4\n",
    "ax3.set_title(\"Filtered dataframe barcode sequences\")\n",
    "ax3.boxplot(\n",
    "    data3, vert=False, widths=0.7,\n",
    "    boxprops=dict(color=\"#d62728\"), whiskerprops=dict(color=\"#d62728\"),\n",
    "    flierprops=dict(marker=\"o\", markersize=3, alpha=0.1, color=\"#d62728\"),\n",
    "    capprops=dict(color=\"#d62728\"), medianprops=dict(color=\"red\")\n",
    ")\n",
    "ax3.axis('off')\n",
    "y_jitter3 = 1 + (np.random.rand(len(data3)) - 0.5) * 2 * jitter_scale\n",
    "ax3.scatter(data3, y_jitter3, s=5, alpha=0.2, color=\"#d62728\")\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "# PDF Histogram on ax4\n",
    "sequences = np.flip(rv35_library[\"counts\"])\n",
    "edge_positions = sequences.searchsorted(bin_edges)\n",
    "counts = np.zeros(len(bin_edges) - 1)\n",
    "for i in range(len(bin_edges) - 1):\n",
    "    parts = edge_positions[i : i + 2]\n",
    "    counts[i] = sequences[parts[0] : parts[1]].sum()\n",
    "counts /= np.sum(sequences)\n",
    "\n",
    "ax4.plot(bin_edges[:-1], counts, drawstyle=\"steps-post\", linewidth=0)\n",
    "ax4.fill_between(bin_edges[:-1], 0, counts, step=\"post\", alpha=0.6, color=\"k\")\n",
    "ax4.set_xlabel(\"Library barcode abundance\")\n",
    "ax4.set_ylabel(r\"Percentage of total library sequences\")\n",
    "ax4.set_xscale(\"log\")\n",
    "ax4.xaxis.set_major_locator(mticker.FixedLocator(locs=np.logspace(0, 6, 5)))\n",
    "ax4.xaxis.set_minor_locator(mticker.LogLocator(numticks=999, subs=\"auto\"))\n",
    "for label in ax4.xaxis.get_ticklabels()[1::2]:\n",
    "    label.set_visible(False)\n",
    "yticks = [0, 0.0125, 0.025, 0.0375, 0.05]\n",
    "ax4.set_yticks(ticks=yticks)\n",
    "ax4.set_yticklabels(labels=[0.00, 1.25, 2.50, 3.75, 5.00])\n",
    "ax4.set_xlim(None, 1000000)\n",
    "ax4.set_ylim(0, 0.05)\n",
    "ax4.yaxis.grid(False)\n",
    "\n",
    "\n",
    "# Enable ticks only for histogram axes\n",
    "for axh in [axh0, axh1, axh2, axh3]:\n",
    "    axh.tick_params(axis='both', which='both', direction='out')  # Show ticks\n",
    "    axh.xaxis.set_visible(True)  # Ensure x-axis is visible\n",
    "    axh.yaxis.set_visible(True)  # Ensure y-axis is visible\n",
    "\n",
    "# Disable ticks for boxplots\n",
    "for ax in [ax0, ax1, ax2, ax3]:\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "\n",
    "# Despine function\n",
    "def despine(ax):\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Apply despine to all subplots\n",
    "for ax in (axh0, ax0, axh1, ax1, axh2, ax2, axh3, ax3, ax4):\n",
    "    despine(ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Define bin edges for consistent binning\n",
    "bin_edges = np.logspace(0, 6, num=80)\n",
    "\n",
    "# Extract histogram data\n",
    "data0 = in_situ_perfect_match[\"ham_lib_bc_counts\"].values\n",
    "data1 = unique_single_pre_no_starter[\"ham_lib_bc_counts\"].values\n",
    "data2 = random_perfect_match[\"lib_bc_counts\"].values\n",
    "\n",
    "# Compute histograms\n",
    "hist0, _ = np.histogram(data0, bins=bin_edges)\n",
    "hist1, _ = np.histogram(data1, bins=bin_edges)\n",
    "hist2, _ = np.histogram(data2, bins=bin_edges)\n",
    "\n",
    "# Normalize histograms (scale max to 1)\n",
    "hist0 = hist0 / np.max(hist0)\n",
    "hist1 = hist1 / np.max(hist1)\n",
    "hist2 = hist2 / np.max(hist2)\n",
    "\n",
    "# Extract and normalize library sequence data\n",
    "sequences = np.flip(rv35_library[\"counts\"])\n",
    "edge_positions = sequences.searchsorted(bin_edges)\n",
    "counts = np.zeros(len(bin_edges) - 1)\n",
    "\n",
    "for i in range(len(bin_edges) - 1):\n",
    "    parts = edge_positions[i : i + 2]\n",
    "    counts[i] = sequences[parts[0] : parts[1]].sum()\n",
    "\n",
    "counts = counts / np.max(counts)  # Normalize to max 1\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot normalized histograms as step-line plots\n",
    "ax.step(bin_edges[:-1], hist0, where=\"post\", color=\"#2ca02c\", linestyle=\"-\", linewidth=2, label=\"All barcode sequences\")\n",
    "ax.step(bin_edges[:-1], hist1, where=\"post\", color=\"#ff7f0e\", linestyle=\"-\", linewidth=2, label=\"Single presyn (no starter)\")\n",
    "ax.step(bin_edges[:-1], hist2, where=\"post\", color=\"#1f77b4\", linestyle=\"-\", linewidth=2, label=\"Randomly generated\")\n",
    "\n",
    "# Plot normalized library sequence data as a dashed black line\n",
    "ax.step(bin_edges[:-1], counts, where=\"post\", color=\"black\", linestyle=\"--\", linewidth=2, label=\"Library sequences\")\n",
    "\n",
    "# X-axis log scale\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "# X-axis formatting\n",
    "ax.set_xlabel(\"Library barcode abundance\")\n",
    "ax.xaxis.set_major_locator(mticker.FixedLocator(locs=np.logspace(0, 6, 5)))\n",
    "ax.xaxis.set_minor_locator(mticker.LogLocator(numticks=999, subs=\"auto\"))\n",
    "\n",
    "# Y-axis label\n",
    "ax.set_ylabel(\"Normalized Frequency\")\n",
    "\n",
    "# Y-axis scale (0 to 1 since everything is normalized)\n",
    "ax.set_xlim(1,1e6)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "# Despine function\n",
    "def despine(ax):\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "despine(ax)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df_counts = random_df[\"min_edit_distance\"].value_counts()\n",
    "in_situ_barcodes_counts = in_situ_barcodes[\"ham_min_edit_distance\"].value_counts()\n",
    "unique_single_pre_no_starter_counts = unique_single_pre_no_starter[\"ham_min_edit_distance\"].value_counts()\n",
    "# Convert counts to DataFrame and calculate percentages\n",
    "df_dict = {\n",
    "    \"Randomly generated\": random_df_counts,\n",
    "    \"All barcode sequences\": in_situ_barcodes_counts,\n",
    "    \"Single presyn (no starter)\": unique_single_pre_no_starter_counts\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(df_dict).fillna(0)\n",
    "df_percentage = df.div(df.sum(axis=0), axis=1) * 100\n",
    "\n",
    "\n",
    "# Plot stacked bar chart with adjusted bar width and legend placement\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# Reduce bar width by adjusting bar positions\n",
    "df_percentage.T.plot(kind='bar', stacked=True, color=[\"black\", \"grey\", \"lightgrey\"], ax=ax, width=0.7)\n",
    "\n",
    "ax.set_ylabel(\"Percentage of Total Sequences (%)\")\n",
    "ax.set_title(\"Minimum Hamming Distance Distribution\")\n",
    "\n",
    "# Move legend outside the plot to the right\n",
    "ax.legend(title=\"Hamming Distance\", labels=[\"0\", \"1\", \"2\"], bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara_is_starters_exploded = ara_is_starters.explode([\"all_barcodes\", \"n_spots_per_barcode\"])\n",
    "# Select barcodes with exactly 1 spot\n",
    "barcodes_with_3_spots = ara_is_starters_exploded[ara_is_starters_exploded[\"n_spots_per_barcode\"] == 1][\"all_barcodes\"]\n",
    "\n",
    "# Select barcodes with more than 20 spots\n",
    "barcodes_with_over_20_spots = ara_is_starters_exploded[ara_is_starters_exploded[\"n_spots_per_barcode\"] > 20][\"all_barcodes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Separate data into with and without starters from ara_is_starters_exploded\n",
    "barcodes_with_starter = ara_is_starters_exploded[ara_is_starters_exploded['is_starter']]\n",
    "barcodes_without_starter = ara_is_starters_exploded[ara_is_starters_exploded['is_starter']==False]\n",
    "\n",
    "# Select barcodes with exactly 1 spot\n",
    "barcodes_with_3_spots = ara_is_starters_exploded[ara_is_starters_exploded[\"n_spots_per_barcode\"] == 3][\"all_barcodes\"]\n",
    "\n",
    "# Select barcodes with more than 20 spots\n",
    "barcodes_with_over_20_spots = ara_is_starters_exploded[ara_is_starters_exploded[\"n_spots_per_barcode\"] > 20][\"all_barcodes\"]\n",
    "\n",
    "# Create separate barcode groups\n",
    "barcodes_with_3_spots_with_starter = barcodes_with_3_spots[barcodes_with_3_spots.isin(barcodes_with_starter[\"all_barcodes\"])]\n",
    "barcodes_with_3_spots_without_starter = barcodes_with_3_spots[~barcodes_with_3_spots.isin(barcodes_with_starter[\"all_barcodes\"])]\n",
    "barcodes_with_over_20_spots_with_starter = barcodes_with_over_20_spots[barcodes_with_over_20_spots.isin(barcodes_with_starter[\"all_barcodes\"])]\n",
    "barcodes_with_over_20_spots_without_starter = barcodes_with_over_20_spots[~barcodes_with_over_20_spots.isin(barcodes_with_starter[\"all_barcodes\"])]\n",
    "\n",
    "\n",
    "# Get unique barcode lists\n",
    "unique_single_pre_no_starter = barcodes_with_3_spots_without_starter.unique()\n",
    "unique_single_pre_with_starter= barcodes_with_3_spots_with_starter.unique()\n",
    "unique_many_pre_no_starter = barcodes_with_over_20_spots_without_starter.unique()\n",
    "unique_many_pre_with_starter = barcodes_with_over_20_spots_with_starter.unique()\n",
    "\n",
    "# Function to calculate base proportions\n",
    "def calculate_base_proportions(sequences):\n",
    "    base_counts = {'A': [0]*10, 'T': [0]*10, 'C': [0]*10, 'G': [0]*10}\n",
    "    for sequence in sequences:\n",
    "        for i, base in enumerate(sequence):\n",
    "            base_counts[base][i] += 1\n",
    "    total_sequences = len(sequences)\n",
    "    if total_sequences > 0:\n",
    "        for base in base_counts:\n",
    "            base_counts[base] = [count / total_sequences for count in base_counts[base]]\n",
    "    return base_counts\n",
    "\n",
    "# Calculate proportions for both sets\n",
    "base_proportions_many_without = calculate_base_proportions(unique_many_pre_no_starter)\n",
    "base_proportions_single_without = calculate_base_proportions(unique_single_pre_no_starter)\n",
    "base_proportions_many_with = calculate_base_proportions(unique_many_pre_with_starter)\n",
    "base_proportions_single_with = calculate_base_proportions(unique_single_pre_with_starter)\n",
    "\n",
    "positions = np.arange(10)\n",
    "bar_width = 0.4\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot for non_starter_without_starter\n",
    "ax1.bar(positions - bar_width/2, base_proportions_many_without['A'], bar_width, label='A (>20 spots per cell)', color='red')\n",
    "ax1.bar(positions - bar_width/2, base_proportions_many_without['T'], bar_width, bottom=base_proportions_many_without['A'], label='T (>20 spots per cell)', color='green')\n",
    "ax1.bar(positions - bar_width/2, base_proportions_many_without['C'], bar_width, bottom=np.array(base_proportions_many_without['A']) + np.array(base_proportions_many_without['T']), label='C (>20 spots per cell)', color='cyan')\n",
    "ax1.bar(positions - bar_width/2, base_proportions_many_without['G'], bar_width, bottom=np.array(base_proportions_many_without['A']) + np.array(base_proportions_many_without['T']) + np.array(base_proportions_many_without['C']), label='G (>20 spots per cell)', color='magenta')\n",
    "\n",
    "ax1.bar(positions + bar_width/2, base_proportions_single_without['A'], bar_width, label='A (3 spots per cell)', color='red', alpha=0.3)\n",
    "ax1.bar(positions + bar_width/2, base_proportions_single_without['T'], bar_width, bottom=base_proportions_single_without['A'], label='T (3 spots per cell)', color='green', alpha=0.3)\n",
    "ax1.bar(positions + bar_width/2, base_proportions_single_without['C'], bar_width, bottom=np.array(base_proportions_single_without['A']) + np.array(base_proportions_single_without['T']), label='C (3 spots per cell)', color='cyan', alpha=0.3)\n",
    "ax1.bar(positions + bar_width/2, base_proportions_single_without['G'], bar_width, bottom=np.array(base_proportions_single_without['A']) + np.array(base_proportions_single_without['T']) + np.array(base_proportions_single_without['C']), label='G (3 spots per cell)', color='magenta', alpha=0.3)\n",
    "\n",
    "ax1.set_xlabel('Position in Sequence')\n",
    "ax1.set_ylabel('Proportion')\n",
    "ax1.set_title('Proportion of Bases at Each Position (Without Starter)')\n",
    "ax1.set_xticks(positions)\n",
    "ax1.set_xticklabels(positions + 1)\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Plot for non_starter_with_starter\n",
    "ax2.bar(positions - bar_width/2, base_proportions_many_with['A'], bar_width, label='A (>20 spots per cell)', color='red')\n",
    "ax2.bar(positions - bar_width/2, base_proportions_many_with['T'], bar_width, bottom=base_proportions_many_with['A'], label='T (>20 spots per cell)', color='green')\n",
    "ax2.bar(positions - bar_width/2, base_proportions_many_with['C'], bar_width, bottom=np.array(base_proportions_many_with['A']) + np.array(base_proportions_many_with['T']), label='C (>20 spots per cell)', color='cyan')\n",
    "ax2.bar(positions - bar_width/2, base_proportions_many_with['G'], bar_width, bottom=np.array(base_proportions_many_with['A']) + np.array(base_proportions_many_with['T']) + np.array(base_proportions_many_with['C']), label='G (>20 spots per cell)', color='magenta')\n",
    "\n",
    "ax2.bar(positions + bar_width/2, base_proportions_single_with['A'], bar_width, label='A (3 spots per cell)', color='red', alpha=0.3)\n",
    "ax2.bar(positions + bar_width/2, base_proportions_single_with['T'], bar_width, bottom=base_proportions_single_with['A'], label='T (3 spots per cell)', color='green', alpha=0.3)\n",
    "ax2.bar(positions + bar_width/2, base_proportions_single_with['C'], bar_width, bottom=np.array(base_proportions_single_with['A']) + np.array(base_proportions_single_with['T']), label='C (3 spots per cell)', color='cyan', alpha=0.3)\n",
    "ax2.bar(positions + bar_width/2, base_proportions_single_with['G'], bar_width, bottom=np.array(base_proportions_single_with['A']) + np.array(base_proportions_single_with['T']) + np.array(base_proportions_single_with['C']), label='G (3 spots per cell)', color='magenta', alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Position in Sequence')\n",
    "ax2.set_ylabel('Proportion')\n",
    "ax2.set_title('Proportion of Bases at Each Position (With Starter)')\n",
    "ax2.set_xticks(positions)\n",
    "ax2.set_xticklabels(positions + 1)\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit distance to nearest starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_barcodes = ara_is_starters[ara_is_starters[\"is_starter\"] == True][\"all_barcodes\"].explode().unique()\n",
    "\n",
    "\n",
    "# Group and filter for non_starter_without_starter\n",
    "grouped_barcodes_without = non_starter_without_starter.groupby('all_barcodes')\n",
    "groups_of_size_1_without = grouped_barcodes_without.filter(lambda x: len(x) == 1)\n",
    "groups_of_size_over_10_without = grouped_barcodes_without.filter(lambda x: len(x) > 10)\n",
    "unique_single_pre_no_starter = groups_of_size_1_without.all_barcodes.unique()\n",
    "unique_many_pre_no_starter = groups_of_size_over_10_without.all_barcodes.unique()\n",
    "\n",
    "# Group and filter for non_starter_with_starter\n",
    "grouped_barcodes_with = non_starter_with_starter.groupby('all_barcodes')\n",
    "groups_of_size_1_with = grouped_barcodes_with.filter(lambda x: len(x) == 1)\n",
    "groups_of_size_over_10_with = grouped_barcodes_with.filter(lambda x: len(x) > 10)\n",
    "unique_single_pre_with_starter = groups_of_size_1_with.all_barcodes.unique()\n",
    "unique_many_pre_with_starter = groups_of_size_over_10_with.all_barcodes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming distance function - used for final plots\n",
    "def hamming_distance(str1, str2):\n",
    "    return sum(c1 != c2 for c1, c2 in zip(str1, str2))\n",
    "\n",
    "# Define a function to calculate the minimum edit distance\n",
    "def calculate_min_edit_distance(insitu_bc):\n",
    "    edit_distances = np.fromiter(\n",
    "        (hamming_distance(insitu_bc, lib_bc) for lib_bc in starter_barcodes[\"10bp_seq\"]), int\n",
    "    )\n",
    "    min_edit_distance_idx = np.argmin(edit_distances)\n",
    "    min_edit_distance = edit_distances[min_edit_distance_idx]\n",
    "    lib_bc_sequence = starter_barcodes.loc[min_edit_distance_idx, \"10bp_seq\"]\n",
    "    return min_edit_distance, lib_bc_sequence\n",
    "\n",
    "# Assuming starter_barcodes and unique_single_pre_no_starter are already defined as lists of sequences\n",
    "starter_barcodes = pd.DataFrame(starter_barcodes, columns=[\"10bp_seq\"])\n",
    "unique_single_pre_no_starter = pd.DataFrame(unique_single_pre_no_starter, columns=[\"sequence\"])\n",
    "unique_many_pre_no_starter = pd.DataFrame(unique_many_pre_no_starter, columns=[\"sequence\"])\n",
    "\n",
    "# Wrap the outer loop with tqdm for progress tracking\n",
    "with Pool() as pool:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            pool.imap(calculate_min_edit_distance, unique_single_pre_no_starter[\"sequence\"]),\n",
    "            total=len(unique_single_pre_no_starter),\n",
    "            desc=\"Calculating edit distances\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Extract the results from the list of tuples\n",
    "min_edit_distances, starter_sequences = zip(*results)\n",
    "\n",
    "# Assign the minimum edit distances, lib_bc sequences, and counts to new columns in unique_single_pre_no_starter\n",
    "unique_single_pre_no_starter[\"ham_min_edit_distance\"] = min_edit_distances\n",
    "unique_single_pre_no_starter[\"starter_sequence\"] = starter_sequences\n",
    "\n",
    "# Wrap the outer loop with tqdm for progress tracking\n",
    "with Pool() as pool:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            pool.imap(calculate_min_edit_distance, unique_many_pre_no_starter[\"sequence\"]),\n",
    "            total=len(unique_many_pre_no_starter),\n",
    "            desc=\"Calculating edit distances\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Extract the results from the list of tuples\n",
    "min_edit_distances, starter_sequences = zip(*results)\n",
    "\n",
    "# Assign the minimum edit distances, lib_bc sequences, and counts to new columns in unique_many_pre_no_starter\n",
    "unique_many_pre_no_starter[\"ham_min_edit_distance\"] = min_edit_distances\n",
    "unique_many_pre_no_starter[\"starter_sequence\"] = starter_sequences\n",
    "\n",
    "\n",
    "# Wrap the outer loop with tqdm for progress tracking\n",
    "with Pool() as pool:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            pool.imap(calculate_min_edit_distance, random_df[\"random_sequences\"]),\n",
    "            total=len(random_df),\n",
    "            desc=\"Calculating edit distances\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Extract the results from the list of tuples\n",
    "min_edit_distances, starter_sequences = zip(*results)\n",
    "\n",
    "# Assign the minimum edit distances, lib_bc sequences, and counts to new columns in unique_many_pre_no_starter\n",
    "random_df[\"ham_min_edit_distance\"] = min_edit_distances\n",
    "random_df[\"starter_sequence\"] = starter_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_many_pre_no_starter.ham_min_edit_distance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_single_pre_no_starter.ham_min_edit_distance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df.ham_min_edit_distance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_many_pre_no_starter_counts = unique_many_pre_no_starter[\"ham_min_edit_distance\"].value_counts()\n",
    "unique_single_pre_no_starter_counts = unique_single_pre_no_starter[\"ham_min_edit_distance\"].value_counts()\n",
    "random_counts = random_df[\"ham_min_edit_distance\"].value_counts()\n",
    "# Convert counts to DataFrame and calculate percentages\n",
    "df_dict = {\n",
    "    \">10 presyn cells no starter\": unique_many_pre_no_starter_counts,\n",
    "    \"Single presyn (no starter)\": unique_single_pre_no_starter_counts,\n",
    "    \"Randomly generated sequences\": random_counts\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(df_dict).fillna(0)\n",
    "df_percentage = df.div(df.sum(axis=0), axis=1) * 100\n",
    "\n",
    "\n",
    "# Plot stacked bar chart with adjusted bar width and legend placement\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Reduce bar width by adjusting bar positions\n",
    "df_percentage.T.plot(kind='bar', stacked=True, color=[\"red\", \"black\", \"grey\", \"lightgrey\", \"whitesmoke\"], ax=ax, width=0.7, edgecolor='black')\n",
    "\n",
    "ax.set_ylabel(\"Percentage of Total Sequences (%)\")\n",
    "ax.set_title(\"Minimum Hamming Distance Distribution to Starter Barcodes\")\n",
    "\n",
    "# Move legend outside the plot to the right\n",
    "ax.legend(title=\"Hamming Distance\", labels=[\"0\", \"1\", \"2\", \"3\", \"4\"], bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "\n",
    "plt.xticks(rotation=0, ) #ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
