{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brisc.manuscript_analysis import connectivity_matrices as conn_mat\n",
    "from brisc.manuscript_analysis import distance_between_cells as dist\n",
    "from brisc.manuscript_analysis import bootstrapping as boot\n",
    "from brisc.manuscript_analysis import load\n",
    "from brisc.exploratory_analysis.plot_summary_for_all_bc import (\n",
    "    compute_flatmap_coors,\n",
    "    get_avg_layer_depth,\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42  # for pdfs\n",
    "\n",
    "from iss_preprocess.io import get_processed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = get_processed_path(\"becalia_rabies_barseq/BRAC8498.3e/analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_correction_ds_name = \"BRAC8498.3e_error_corrected_barcodes_26\"\n",
    "df_path = processed_path / f\"{error_correction_ds_name}_cell_barcode_df.pkl\"\n",
    "# Run only once to add gene info\n",
    "if False:\n",
    "    old_df = pd.read_pickle(processed_path / \"cell_barcode_df.pkl\")\n",
    "    from brisc.manuscript_analysis.cell_barcode_assignment import assign_cell_barcodes\n",
    "\n",
    "    new_df = assign_cell_barcodes(\n",
    "        error_correction_ds_name=error_correction_ds_name,\n",
    "    )\n",
    "\n",
    "    col2copy = [\"raw_gene_counts\", \"best_score\", \"knn_agree_conf\", \"best_cluster\"]\n",
    "    new_df = pd.merge(\n",
    "        new_df, old_df[col2copy], how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "    new_df.to_pickle(df_path)\n",
    "    coords = new_df[[f\"ara_{o}\" for o in \"xyz\"]]\n",
    "    print(coords.isna().values.any(1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data\")\n",
    "cells_df = load.load_cell_barcode_data(\n",
    "    processed_path,\n",
    "    areas_to_empty=[\"fiber tracts\", \"outside\"],\n",
    "    valid_areas=[\"Isocortex\", \"TH\"],\n",
    "    distance_threshold=150,\n",
    "    error_correction_ds_name=error_correction_ds_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Projection on flatmap\")\n",
    "flat_coors = compute_flatmap_coors(cells_df, distance_cutoff=150)\n",
    "cells_df[\"flatmap_x\"] = flat_coors[:, 0]\n",
    "cells_df[\"flatmap_y\"] = flat_coors[:, 1]\n",
    "cells_df[\"flatmap_z\"] = flat_coors[:, 2]\n",
    "\n",
    "normalised_coors = compute_flatmap_coors(cells_df, distance_cutoff=150, thickness_type='normalized_layers')\n",
    "# keep x/y too even if they're the same as non normalised to make it easier for later\n",
    "# functions\n",
    "\n",
    "cells_df[\"flatmap_x_normalised\"] = np.array(normalised_coors[:, 0])\n",
    "cells_df[\"flatmap_y_normalised\"] = np.array(normalised_coors[:, 1])\n",
    "cells_df[\"flatmap_z_normalised\"] = np.array(normalised_coors[:, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,1,1, aspect='equal')\n",
    "moved = cells_df.query('was_in_wm == True')\n",
    "non_moved = cells_df.query('was_in_wm == False')\n",
    "plt.scatter(non_moved.ara_z, non_moved.ara_y)\n",
    "plt.scatter(moved.ara_z, moved.ara_y)\n",
    "plt.xlim(4,22)\n",
    "plt.ylim(5, 0)\n",
    "\n",
    "plt.scatter(non_moved.flatmap_x/100+10, non_moved.flatmap_z_normalised/100)\n",
    "plt.scatter(moved.flatmap_x/100+10, moved.flatmap_z_normalised/100)\n",
    "for _, m in moved.iterrows():\n",
    "    plt.plot([m.ara_z, m.flatmap_x/100+10],[m.ara_y, m.flatmap_z_normalised/100],color='k', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,1,1, aspect='equal')\n",
    "moved = cells_df.query('was_in_wm == True')\n",
    "non_moved = cells_df.query('was_in_wm == False')\n",
    "for _, m in moved.iterrows():\n",
    "    plt.plot([m.ara_z, m.flatmap_x/100+10],[m.ara_y, m.flatmap_z/100],color='k', alpha=0.2)\n",
    "plt.scatter(non_moved.ara_z, non_moved.ara_y)\n",
    "plt.scatter(moved.ara_z, moved.ara_y)\n",
    "plt.xlim(4,22)\n",
    "\n",
    "plt.scatter(non_moved.flatmap_x/100+10, non_moved.flatmap_z/100)\n",
    "plt.scatter(moved.flatmap_x/100+10, moved.flatmap_z/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = \"flatmap_dorsal\"\n",
    "thickness_type = 'normalized_layers'\n",
    "from brisc.exploratory_analysis import plot_summary_for_all_bc as psa\n",
    "ori_coors = moved[[f\"ara_{c}\" for c in 'xyz']].values \n",
    "flat_coors = np.zeros_like(ori_coors)\n",
    "bad = np.any(ori_coors <= 0, axis=1)\n",
    "# also remove NaN\n",
    "bad = np.logical_or(bad, np.any(np.isnan(ori_coors), axis=1))\n",
    "if np.any(bad):\n",
    "    print(f\"Found {np.sum(bad)} bad coordinates\")\n",
    "    flat_coors[bad, :] = np.nan\n",
    "ccf_coord_proj = psa.get_projector(projection)\n",
    "if projection == \"flatmap_dorsal\":\n",
    "    view_space = \"flatmap_dorsal\"\n",
    "elif projection == \"top\":\n",
    "    view_space = False\n",
    "else:\n",
    "    print(f\"Warning unknown projections: {projection}.\")\n",
    "    view_space = False\n",
    "print(np.sum(bad), len(ori_coors))\n",
    "flat_coors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_coors[~bad, :] = ccf_coord_proj.project_coordinates(\n",
    "        ori_coors[~bad, :] * 1000,\n",
    "        drop_voxels_outside_view_streamlines=False,\n",
    "        view_space_for_other_hemisphere=view_space,\n",
    "        hemisphere=\"right\",\n",
    "        thickness_type=thickness_type,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_move = np.isnan(flat_coors[:, 0])\n",
    "print(to_move.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,1,1, aspect='equal')\n",
    "valid_voxels = ccf_coord_proj.closest_surface_voxels[:, 0]\n",
    "valid_voxels = np.vstack(\n",
    "    np.unravel_index(valid_voxels, np.array(ccf_coord_proj.volume_shape))\n",
    ").T\n",
    "# Find voxels of points to move\n",
    "ori_voxel = (ori_coors[to_move, :] * 1000 / ccf_coord_proj.resolution).astype(int)\n",
    "plt.scatter(ori_voxel[:,2], ori_voxel[:,1])\n",
    "z_size = ccf_coord_proj.volume_shape[2]\n",
    "z_midline = z_size / 2\n",
    "# reflect to left hemisphere\n",
    "to_reflect = ori_voxel[:, 2] > z_midline\n",
    "ori_voxel[to_reflect, 2] = z_size - ori_voxel[to_reflect, 2]\n",
    "plt.scatter(ori_voxel[:,2], ori_voxel[:,1])\n",
    "plt.axvline(z_midline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "distance_cutoff = 150\n",
    "min_v, max_v = ori_voxel.min(axis=0), ori_voxel.max(axis=0)\n",
    "dst_cutoff = distance_cutoff / ccf_coord_proj.resolution[0]\n",
    "print(dst_cutoff)\n",
    "print(min_v)\n",
    "print(max_v)\n",
    "lower_bounds = min_v - dst_cutoff\n",
    "upper_bounds = max_v + dst_cutoff\n",
    "is_within_bounds = np.all(\n",
    "    (valid_voxels >= lower_bounds) & (valid_voxels <= upper_bounds), axis=1\n",
    ")\n",
    "valid_voxels = valid_voxels[is_within_bounds, :]\n",
    "distances, closest_voxels = np.zeros(ori_voxel.shape[0]), np.zeros_like(ori_voxel)\n",
    "for i, voxel in tqdm(\n",
    "    enumerate(ori_voxel),\n",
    "    total=ori_voxel.shape[0],\n",
    "    desc=\"Find closest voxel that can be projected to flatmap\",\n",
    "):\n",
    "    # keep valid_voxels in a dst_cutoff cube around voxel\n",
    "    upper = voxel + dst_cutoff\n",
    "    lower = voxel - dst_cutoff\n",
    "    is_within = np.all((valid_voxels >= lower) & (valid_voxels <= upper), axis=1)\n",
    "    vvox = valid_voxels[is_within, :]\n",
    "    dst = np.linalg.norm(vvox - voxel, axis=-1)\n",
    "    if not len(dst):\n",
    "        distances[i] = np.inf\n",
    "        continue\n",
    "    distances[i] = dst.min()\n",
    "    closest_voxels[i] = vvox[dst.argmin(), :]\n",
    "close_enough = distances < dst_cutoff\n",
    "print(f\"Found {np.sum(close_enough)}/{ori_voxel.shape[0]} close enough\")\n",
    "# put them back in the right hemisphere if needed\n",
    "closest_reflected = closest_voxels.copy()\n",
    "closest_reflected[to_reflect, 2] = z_size - closest_reflected[to_reflect, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,1,1, aspect='equal')\n",
    "for o, c in zip(ori_voxel[close_enough], closest_voxels[close_enough]):\n",
    "    plt.plot([o[2], c[2]], [o[1], c[1]], color='k')\n",
    "plt.scatter(ori_voxel[close_enough,2], ori_voxel[close_enough,1])\n",
    "plt.scatter(closest_voxels[close_enough,2], closest_voxels[close_enough,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprojected = np.empty(closest_voxels.shape) + np.nan\n",
    "reprojected[close_enough, :] = ccf_coord_proj.project_coordinates(\n",
    "    (closest_reflected[close_enough, :] * ccf_coord_proj.resolution[0]).astype(float),\n",
    "    drop_voxels_outside_view_streamlines=False,\n",
    "    view_space_for_other_hemisphere=view_space,\n",
    "    hemisphere=\"both\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_coord_proj.resolution[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_cells = cells_df[\n",
    "    (~cells_df[\"cortical_area\"].isna())\n",
    "    & ~(cells_df.cortical_area.isin([\"TH\", \"hippocampal\"]))\n",
    "]\n",
    "print(\n",
    "    f\"{ctx_cells.flatmap_x.isna().sum()}/{ctx_cells.shape[0]} cortical cells have no flatmap coordinates\"\n",
    ")\n",
    "print(\"Matching barcodes\")\n",
    "conn_mat.match_barcodes(cells_df)\n",
    "dist.add_connection_distances(cells_df, cols=[\"flatmap_x\", \"flatmap_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_excitatory_cell_types = [\"Vip\", \"Sst\", \"Pvalb\", \"Lamp5\", \"VLMC\"]\n",
    "non_excitatory = cells_df[\"best_cluster\"].isin(non_excitatory_cell_types)\n",
    "\n",
    "cells_df = cells_df[~non_excitatory]\n",
    "layers = [\"L2/3\", \"L4\", \"L5\", \"L6a\", \"L6b\"]\n",
    "# local connections\n",
    "cells_df = cells_df[cells_df[\"cortical_layer\"].notnull()]\n",
    "# change any cells with cells_df[\"cortical_layer\"] == \"L1\" to \"L2,3\"\n",
    "cells_df.loc[cells_df[\"cortical_layer\"] == \"L1\", \"cortical_layer\"] = \"L2/3\"\n",
    "cells_df = cells_df[cells_df[\"cortical_layer\"].apply(lambda layer: layer in layers)]\n",
    "cells_df = cells_df[cells_df[\"distances\"].apply(lambda dist: np.max(dist)) < 100]\n",
    "\n",
    "grouping = \"cortical_layer\"  # \"area_acronym_ancestor_rank1\"\n",
    "# Shuffle the barcodes assigned to each cell in the connectivity matrix\n",
    "(\n",
    "    shuffled_cell_barcode_dfs,\n",
    "    shuffled_matrices,\n",
    "    mean_input_fraction_dfs,\n",
    "    starter_input_fractions,\n",
    "    _,\n",
    ") = conn_mat.shuffle_and_compute_connectivity(\n",
    "    cells_df,\n",
    "    n_permutations=1000,\n",
    "    shuffle_starters=False,\n",
    "    shuffle_presyn=True,\n",
    "    starter_grouping=grouping,\n",
    "    presyn_grouping=grouping,\n",
    "    output_fraction=False,\n",
    ")\n",
    "\n",
    "(\n",
    "    shuffled_cell_barcode_dfs,\n",
    "    shuffled_matrices,\n",
    "    output_fraction_dfs,\n",
    "    _,\n",
    "    _,\n",
    ") = conn_mat.shuffle_and_compute_connectivity(\n",
    "    cells_df,\n",
    "    n_permutations=1000,\n",
    "    shuffle_starters=False,\n",
    "    shuffle_presyn=True,\n",
    "    starter_grouping=grouping,\n",
    "    presyn_grouping=grouping,\n",
    "    output_fraction=True,\n",
    ")\n",
    "\n",
    "connectivity_matrix, mean_input_fraction, fractions_df, _ = (\n",
    "    conn_mat.compute_connectivity_matrix(\n",
    "        cells_df,\n",
    "        starter_grouping=grouping,\n",
    "        presyn_grouping=grouping,\n",
    "        output_fraction=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "connectivity_matrix, output_fraction, _, _ = conn_mat.compute_connectivity_matrix(\n",
    "    cells_df,\n",
    "    starter_grouping=grouping,\n",
    "    presyn_grouping=grouping,\n",
    "    output_fraction=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fraction_log_ratio, input_fraction_pval = conn_mat.compare_to_shuffle(\n",
    "    *conn_mat.filter_matrices(\n",
    "        mean_input_fraction,\n",
    "        np.array(mean_input_fraction_dfs),\n",
    "        row_order=layers,\n",
    "        col_order=layers,\n",
    "    )\n",
    ")\n",
    "\n",
    "output_fraction_log_ratio, output_fraction_pval = conn_mat.compare_to_shuffle(\n",
    "    *conn_mat.filter_matrices(\n",
    "        output_fraction,\n",
    "        np.array(output_fraction_dfs),\n",
    "        row_order=layers,\n",
    "        col_order=layers,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\"L2/3\", \"L4\", \"L5\", \"L6a\", \"L6b\"]\n",
    "\n",
    "counts_df, mean_input_frac_df, fractions_df, _ = conn_mat.compute_connectivity_matrix(\n",
    "    cells_df,\n",
    "    starter_grouping=\"cortical_layer\",  # \"area_acronym_ancestor_rank1\",\n",
    "    presyn_grouping=\"cortical_layer\",  # \"area_acronym_ancestor_rank1\",\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create bootstrap samples\n",
    "nboot = 1000\n",
    "bootstrap_samples = []\n",
    "\n",
    "for i in tqdm(range(nboot)):\n",
    "    rows = []\n",
    "    for layer, group in fractions_df.groupby(\"cortical_layer\", observed=True):\n",
    "        this_layer = group.sample(n=len(group), replace=True)[layers].mean()\n",
    "        this_layer.name = layer\n",
    "        rows.append(this_layer)  # Resample with replacement\n",
    "    bootstrap_samples.append(pd.concat(rows, axis=1))\n",
    "bootstrap_samples = np.array(bootstrap_samples)\n",
    "lower_df = pd.DataFrame(\n",
    "    data=np.quantile(bootstrap_samples, 0.025, axis=0), index=layers, columns=layers\n",
    ")\n",
    "upper_df = pd.DataFrame(\n",
    "    data=np.quantile(bootstrap_samples, 0.975, axis=0), index=layers, columns=layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = {\n",
    "    \"L2/3\": \"2/3\",\n",
    "    \"L4\": \"4\",\n",
    "    \"L5\": \"5\",\n",
    "    \"L6a\": \"6a\",\n",
    "    \"L6b\": \"6b\",\n",
    "}\n",
    "presynaptic_counts = conn_mat.reorganise_matrix(counts_df).sum(axis=1)\n",
    "starter_counts = fractions_df.value_counts(\"cortical_layer\").rename(index=areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brisc.manuscript_analysis import distance_between_cells as dist_cells\n",
    "\n",
    "relative_presyn_coords_flatmap, distancess_flatmap, starters_df = (\n",
    "    dist_cells.determine_presynaptic_distances(cells_df, col_prefix=\"flatmap_\", col_suffix='_normalised')\n",
    ")\n",
    "alllayers = [\"L1\"] + layers + [\"WM\"]\n",
    "starters_df[\"layer_index\"] = starters_df.cortical_layer.map(\n",
    "    lambda x: alllayers.index(x) if x in alllayers else np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Fig.1\n",
    "save_fig = False\n",
    "\n",
    "fontsize_dict = {\"title\": 7, \"label\": 7, \"tick\": 6, \"legend\": 6}\n",
    "pad_dict = {\"label\": 1, \"tick\": 1, \"legend\": 5}\n",
    "line_width = 0.9\n",
    "line_alpha = 1\n",
    "\n",
    "cm = 1 / 2.54\n",
    "fig = plt.figure(figsize=(17.4 * cm, 17.4 * cm), dpi=200)\n",
    "\n",
    "save_path = Path(\"Z:/home/shared/presentations/becalick_2025\")\n",
    "# save_path = Path(\"/nemo/lab/znamenskiyp/home/shared/presentations/becalick_2025\")\n",
    "\n",
    "\n",
    "figname = \"matrices\"\n",
    "\n",
    "\n",
    "if True:\n",
    "    frame = fig.add_axes([0, 0, 1, 1])\n",
    "    frame.set_xticks([])\n",
    "    frame.set_yticks([])\n",
    "\n",
    "# Presynaptic scatters\n",
    "w = 0.17\n",
    "scl = 10  # scale to put distance in um\n",
    "avg_layer_tops = get_avg_layer_depth()\n",
    "layer_borders = np.hstack([0, np.sort(np.hstack(list(avg_layer_tops.values()))), 1200])\n",
    "midlayer = np.diff(layer_borders) / 2 + layer_borders[:-1]\n",
    "ax_layers = []\n",
    "\n",
    "for il, layer in enumerate(layers):\n",
    "    axl = fig.add_axes([0.05 + (w + 0.01) * il, 0.6, w, 0.2], aspect=\"equal\")\n",
    "    for d in layer_borders[:-1]:\n",
    "        axl.axhline(d, ls=\"--\", lw=0.5, color=\"lightgray\")\n",
    "    this_layer = starters_df[starters_df[\"cortical_layer\"] == layer]\n",
    "\n",
    "    rel_ap = np.hstack(this_layer[\"presynaptic_coors_relative\"].values)[0][:, 0] * scl\n",
    "    rel_ml = np.hstack(this_layer[\"presynaptic_coors_relative\"].values)[0][:, 1] * scl\n",
    "    abs_depth = np.hstack(this_layer[\"presynaptic_coors\"].values)[0][:, 2] * scl\n",
    "    plt.scatter(\n",
    "        rel_ml, abs_depth, marker=\".\", color=\"darkred\", alpha=0.5, ec=\"w\", lw=0.1, s=10\n",
    "    )\n",
    "    plt.scatter(\n",
    "        np.zeros(len(this_layer)),\n",
    "        this_layer[\"flatmap_z_normalised\"] * scl,\n",
    "        marker=\".\",\n",
    "        color=\"k\",\n",
    "        s=20,\n",
    "        alpha=0.3,\n",
    "        ec=\"None\",\n",
    "    )\n",
    "    axl.set_xlim(-800, 800)\n",
    "    axl.set_ylim(1350, -50)\n",
    "    if il == 0:\n",
    "        axl.set_title(\n",
    "            f\"Starter layer:     {layer[1:]}\", fontsize=fontsize_dict[\"title\"]\n",
    "        )\n",
    "        rec = plt.Rectangle((-680, 1200), 200, 30, color=\"k\")\n",
    "        axl.add_artist(rec)\n",
    "    else:\n",
    "        axl.set_title(layer[1:], fontsize=fontsize_dict[\"title\"])\n",
    "    axl.set_axis_off()\n",
    "for il, layer in enumerate([\"L1\"] + layers + [\" WM\"]):\n",
    "    axl.text(\n",
    "        750,\n",
    "        midlayer[il],\n",
    "        layer[1:],\n",
    "        fontsize=fontsize_dict[\"legend\"],\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Raw counts\n",
    "ax_counts = fig.add_axes([0.07, 0.35, 0.2, 0.2])\n",
    "conn_mat.plot_area_by_area_connectivity(\n",
    "    conn_mat.reorganise_matrix(counts_df, areas=areas),\n",
    "    starter_counts,\n",
    "    presynaptic_counts,\n",
    "    ax_counts,\n",
    "    input_fraction=False,\n",
    "    odds_ratio=False,\n",
    "    label_fontsize=fontsize_dict[\"label\"],\n",
    "    tick_fontsize=fontsize_dict[\"tick\"],\n",
    "    line_width=line_width,\n",
    ")\n",
    "\n",
    "# Input fraction\n",
    "ax_input_fraction = fig.add_axes([0.28, 0.35, 0.2, 0.2])\n",
    "ax_input_fraction_cb = fig.add_axes([0.49, 0.35, 0.01, 0.05])\n",
    "conn_mat.plot_area_by_area_connectivity(\n",
    "    conn_mat.reorganise_matrix(mean_input_fraction, areas=areas),\n",
    "    starter_counts,\n",
    "    presynaptic_counts,\n",
    "    ax_input_fraction,\n",
    "    input_fraction=True,\n",
    "    odds_ratio=False,\n",
    "    label_fontsize=fontsize_dict[\"label\"],\n",
    "    tick_fontsize=fontsize_dict[\"tick\"],\n",
    "    line_width=line_width,\n",
    "    show_counts=False,\n",
    "    cbax=ax_input_fraction_cb,\n",
    "    cbar_label=\"Input\\nfraction\",\n",
    ")\n",
    "ax_input_fraction.set_ylabel(\"\")\n",
    "ax_input_fraction.set_yticks([])\n",
    "\n",
    "# Confidence interval of input fraction\n",
    "ax_input_fraction_bars = fig.add_axes([0.61, 0.37, 0.25, 0.18])\n",
    "boot.plot_confidence_intervals(\n",
    "    conn_mat.reorganise_matrix(mean_input_frac_df, areas=areas),\n",
    "    conn_mat.reorganise_matrix(lower_df, areas=areas),\n",
    "    conn_mat.reorganise_matrix(upper_df, areas=areas),\n",
    "    ax_input_fraction_bars,\n",
    "    label_fontsize=fontsize_dict[\"label\"],\n",
    "    tick_fontsize=fontsize_dict[\"tick\"],\n",
    "    line_width=line_width,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "\n",
    "# Schematics\n",
    "ax_schematics = fig.add_axes([0.86, 0.39, 0.15, 0.18])\n",
    "cax_schematics = fig.add_axes([0.89, 0.34, 0.01, 0.05])\n",
    "positions = {l: p for l, p in zip(layers, [(2, 6), (0, 5), (2, 4), (0, 3), (2, 2)])}\n",
    "fig, ax, cbar = conn_mat.connectivity_diagram_mpl(\n",
    "    mean_input_fraction,\n",
    "    lower_df,\n",
    "    upper_df,\n",
    "    connection_names=layers,\n",
    "    positions=positions,\n",
    "    display_names=[l[1:] for l in layers],\n",
    "    node_style=dict(facecolor=\"Lightgray\", radius=0.5, fontsize=fontsize_dict[\"title\"]),\n",
    "    min_fraction_cutoff=0.2,\n",
    "    ci_to_alpha=False,\n",
    "    ci_cmap=\"plasma\",\n",
    "    edge_width_scale=10,\n",
    "    arrow_head_scale=20,\n",
    "    arrow_style=dict(connectionstyle=\"Arc3, rad=-0.2\", ec=\"none\"),\n",
    "    ax=ax_schematics,\n",
    "    cax=cax_schematics,\n",
    ")\n",
    "# cbar.set_ticks([0, 0.5, 1])\n",
    "\n",
    "\n",
    "# Bubble plot input fraction\n",
    "ax_bubble_plot_input_frac = fig.add_axes([0.07, 0.05, 0.2, 0.2])\n",
    "ax_bubble_plot_input_frac_cb = fig.add_axes([0.29, 0.2, 0.01, 0.05])\n",
    "conn_mat.bubble_plot(\n",
    "    conn_mat.reorganise_matrix(input_fraction_log_ratio, areas=areas),\n",
    "    conn_mat.reorganise_matrix(input_fraction_pval, areas=areas),\n",
    "    alpha=0.05,\n",
    "    size_scale=250,\n",
    "    ax=ax_bubble_plot_input_frac,\n",
    "    cbax=ax_bubble_plot_input_frac_cb,\n",
    "    label_fontsize=fontsize_dict[\"label\"],\n",
    "    tick_fontsize=fontsize_dict[\"tick\"],\n",
    ")\n",
    "\n",
    "# Output fraction\n",
    "ax_output_fraction = fig.add_axes([0.45, 0.05, 0.2, 0.2])\n",
    "ax_output_fraction_cb = fig.add_axes([0.66, 0.05, 0.01, 0.05])\n",
    "# output_fraction = conn_mat.reorganise_matrix(output_fraction)\n",
    "conn_mat.plot_area_by_area_connectivity(\n",
    "    conn_mat.reorganise_matrix(output_fraction, areas=areas),\n",
    "    starter_counts,\n",
    "    presynaptic_counts,\n",
    "    ax_output_fraction,\n",
    "    cbax=ax_output_fraction_cb,\n",
    "    cbar_label=\"Output\\nfraction\",\n",
    "    input_fraction=True,\n",
    "    odds_ratio=False,\n",
    "    label_fontsize=fontsize_dict[\"label\"],\n",
    "    tick_fontsize=fontsize_dict[\"tick\"],\n",
    "    line_width=line_width,\n",
    "    show_counts=False,\n",
    ")\n",
    "\n",
    "# Bubble plot input fraction\n",
    "ax_bubble_plot_output_frac = fig.add_axes([0.78, 0.05, 0.2, 0.2])\n",
    "conn_mat.bubble_plot(\n",
    "    conn_mat.reorganise_matrix(output_fraction_log_ratio, areas=areas),\n",
    "    conn_mat.reorganise_matrix(output_fraction_pval, areas=areas),\n",
    "    alpha=0.05,\n",
    "    size_scale=250,\n",
    "    ax=ax_bubble_plot_output_frac,\n",
    "    show_legend=False,\n",
    "    label_fontsize=fontsize_dict[\"label\"],\n",
    "    tick_fontsize=fontsize_dict[\"tick\"],\n",
    ")\n",
    "\n",
    "if save_fig:\n",
    "    fig.savefig(save_path / f\"conn_mat.pdf\", format=\"pdf\")\n",
    "    fig.savefig(save_path / f\"conn_mat.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alllayers = [\"L1\"] + layers + [\"WM\"]\n",
    "starters_df[\"layer_index\"] = starters_df.cortical_layer.map(\n",
    "    lambda x: layers.index(x) if x in alllayers else np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainglobe_atlasapi as bga\n",
    "\n",
    "atlas = bga.BrainGlobeAtlas(atlas_name=\"allen_mouse_10um\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = cells_df.query(\"is_starter==True\")\n",
    "st_coords = st[[\"ara_x\", \"ara_y\", \"ara_z\"]].values * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = [\n",
    "    atlas.structure_from_coords(c, as_acronym=True, microns=True) for c in st_coords\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st[\"area_rematch\"] = areas\n",
    "st.loc[(st[\"area_acronym\"] != st[\"area_rematch\"]), [\"area_acronym\", \"area_rematch\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brisc.manuscript_analysis import distance_between_cells as dist_cells\n",
    "\n",
    "relative_presyn_coords_flatmap, distancess_flatmap, starters_df = (\n",
    "    dist_cells.determine_presynaptic_distances(cells_df, col_prefix=\"flatmap_\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "nboot = 1000\n",
    "dist = np.zeros(len(layers))\n",
    "dist_boot = np.zeros((len(layers), nboot))\n",
    "\n",
    "\n",
    "def get_median_dist(starters):\n",
    "    relative_ap = np.hstack(starters[\"presynaptic_coors_relative\"].values)[0][:, 0]\n",
    "    relative_ml = np.hstack(starters[\"presynaptic_coors_relative\"].values)[0][:, 1]\n",
    "    distances = ((relative_ml**2 + relative_ap**2) ** 0.5).astype(float)\n",
    "    return np.nanmedian(distances)\n",
    "\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    this_layer = starters_df[starters_df[\"cortical_layer\"] == layer]\n",
    "    rel_ap = np.hstack(this_layer[\"presynaptic_coors_relative\"].values)[0][:, 0]\n",
    "    rel_ml = np.hstack(this_layer[\"presynaptic_coors_relative\"].values)[0][:, 1]\n",
    "\n",
    "    abs_depth = np.hstack(this_layer[\"presynaptic_coors\"].values)[0][:, 2]\n",
    "    for iboot in range(nboot):\n",
    "        dist_boot[i, iboot] = get_median_dist(\n",
    "            this_layer.sample(replace=True, n=len(this_layer), axis=0)\n",
    "        )\n",
    "    plt.plot(rel_ml, abs_depth, \",k\", alpha=0.5)\n",
    "    # plt.plot(relative_ap, relative_ml, ',k', alpha=0.5)\n",
    "    plt.plot(np.zeros(len(this_layer)), this_layer[\"flatmap_z\"], \".\", color=\"r\")\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.xlim([-100, 100])\n",
    "    plt.ylim([100, 0])\n",
    "\n",
    "    distances = ((rel_ml**2 + rel_ap**2) ** 0.5).astype(float)\n",
    "    dist[i] = np.nanmedian(distances)\n",
    "    print(dist[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
